<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.290">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-11-29">

<title>iammees - Causal Inference Series Part 1: Simpson’s Paradox or Why We Need Causal Inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">iammees</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/iammees" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Causal Inference Series Part 1: Simpson’s Paradox or Why We Need Causal Inference</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 29, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>Whether in academia or industry, research questions are often causal in nature. That is, we want to know whether a medical procedure <em>caused</em> patients to recover, whether a policy intervention <em>caused</em> some behavioral change in the population, whether a new store design <em>caused</em> an increase in sales, or whether a recently implemented feature <em>caused</em> an increase in customer retention. In practice, though, it is surprisingly common to avoid language that refers to causal concepts. A <a href="https://pubmed.ncbi.nlm.nih.gov/35925053/">2022 study by Haber et al.</a> which examined over 1,000 articles published in high-profile medical and epidemiological journals found that even though few articles declared an explicit interest in estimating causal effects, a third of the studies issued action recommendations (implying that a causal mechanism has been found), and the majority of the studies used language that implied causality (e.g., “X affects Y”, “X is linked to Y”, “X is followed by Y”). What we end up with can be called “<a href="https://pubmed.ncbi.nlm.nih.gov/33065609/">Schrödinger’s causal inference</a>”: researchers caution against causal interpretations but still offer causal interpretations themselves. Why is that? Apparently, researchers <em>intend</em> to estimate causal effects but shy away from using the causal inference methods which would actually allow to make this intention explicit. One likely reason is that causal inference goes beyond the realm of traditional statistics, introducing additional assumptions as well as a more rigorous way of thinking about relationships between variables. We can make this more concrete by looking at an example of Simpson’s paradox that will shine a light on why pure statistics isn’t enough to establish causal effects.</p>
<section id="simpsons-paradox" class="level2">
<h2 class="anchored" data-anchor-id="simpsons-paradox">Simpson’s Paradox</h2>
<p>Suppose that until recently, no treatment had been available for some unnamed disease. However, two newly developed treatments, treatment <span class="math inline">\(A\)</span> and treatment <span class="math inline">\(B\)</span>, have shown promise in clinical trials and since became available to medical professionals. While treatment <span class="math inline">\(A\)</span> is a surgical procedure, treatment <span class="math inline">\(B\)</span> is a small molecule drug that blocks a key protein involved in the disease process.</p>
<p>Our task is to analyze the following table which shows the condition of the patient at the time the treatment was decided as well as the corresponding success rates and case counts. Note that, due to supply chain and production issues, treatment <span class="math inline">\(B\)</span> is more scarce than treatment <span class="math inline">\(A\)</span>.</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="simpsons_paradox_table.png" class="quarto-discovered-preview-image img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Treatment data as an example of Simpson’s paradox</figcaption><p></p>
</figure>
</div>
<p>We can see that treatment <span class="math inline">\(B\)</span> had a better recovery rate than treatment <span class="math inline">\(A\)</span> for patients with mild cases (91.3% vs 86.8%), as well as patients with severe cases (80.0% vs 71.4%). However, in the whole population, the patients who were treated with treatment <span class="math inline">\(A\)</span> had a better recovery rate than the patients treated with treatment <span class="math inline">\(B\)</span> (85.3% vs 81.4%). This is an example of <strong>Simpson’s paradox</strong>, a statistical phenomenon in which a statistical association that holds for an entire population is reversed in every subpopulation.</p>
<p>If we had to make the decision which treatment to recommend for a patient, how should we interpret the data? Should we recommend treatment <span class="math inline">\(A\)</span> if we don’t know the condition of the patient and <span class="math inline">\(B\)</span> if we do? That can’t be right; a patient has to be either a mild or a severe case even if we don’t know the condition and <span class="math inline">\(B\)</span> apparently is superior for both conditions. So should we just rely on the segregated data because the success rates of the subpopulations provide more specific information or should we only consult the aggregated success rate because it is more general? In short, which is better: treatment <span class="math inline">\(A\)</span> or treatment <span class="math inline">\(B\)</span>?</p>
<p>It turns out that we cannot answer this question with pure statistics. Without knowing the causal structure of the data, we simply cannot tell whether we should prefer treatment <span class="math inline">\(A\)</span> or treatment <span class="math inline">\(B\)</span>. To understand this key point, let’s consider two different scenarios.</p>
<p><strong>Scenario 1</strong>: In scenario 1, the patient’s condition <span class="math inline">\(C\)</span> is a cause of both the treatment <span class="math inline">\(T\)</span> and the outcome <span class="math inline">\(Y\)</span> (i.e., the recovery of the patient). This would be the case when doctors decide to reserve treatment <span class="math inline">\(B\)</span> for patients with severe conditions (e.g., because it is more expensive or less invasive or both). Then, having a severe condition would cause patients to be less likely to recover (simply because of their condition) <em>and</em> more likely to receive treatment <span class="math inline">\(B\)</span>. It follows that treatment <span class="math inline">\(B\)</span> will be associated with a lower success rate in the entire population just because the patient’s condition is a common cause of both the treatment and the outcome. We say that condition <strong>confounds</strong> the effect of treatment on recovery. We can correct for this <strong>confounding</strong> by analyzing the relationship of <span class="math inline">\(T\)</span> and <span class="math inline">\(Y\)</span> among patients with the same condition. In our example, this would mean that treatment <span class="math inline">\(B\)</span> is the better treatment because it leads to a higher recovery rate in both subpopulations (i.e., the subpopulations with mild and severe cases, respectively). We can visualize the causal structure of this scenario with the following graph:</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="simpsons_paradox_scenario1.png" class="img-fluid figure-img" width="170"></p>
<p></p><figcaption class="figure-caption">Causal diagram of scenario 1</figcaption><p></p>
</figure>
</div>
<p><strong>Scenario 2</strong>: In scenario 2, the <em>prescription</em> of treatment <span class="math inline">\(T\)</span> is a cause of both the patient’s condition <span class="math inline">\(C\)</span> and the outcome <span class="math inline">\(Y\)</span>. This would be the case, for example, when the supply chain issues of treatment <span class="math inline">\(B\)</span> lead to a time delay between the prescription and the reception of the treatment, while treatment <span class="math inline">\(A\)</span> can be applied instantaneously. If the severity of the disease worsens over time, this would mean that the assignment of treatment <span class="math inline">\(B\)</span> can cause patients to transition from mild to severe cases of the disease, ultimately causing a lower recovery rate. In that case we could conclude that, even though treatment <span class="math inline">\(B\)</span> might be more effective than treatment <span class="math inline">\(A\)</span> once received by the patient, prescribing treatment <span class="math inline">\(A\)</span> is overall more effective. The causal diagram highlights the difference to scenario 1:</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="simpsons_paradox_scenario2.png" class="img-fluid figure-img" width="170"></p>
<p></p><figcaption class="figure-caption">Causal diagram of scenario 2</figcaption><p></p>
</figure>
</div>
<p>What should we make of this? Comparing both scenarios shows that, without knowing the story behind the data it is impossible to determine which treatment is better. It was only after considering the causal mechanisms generating the data that we were able to make a correct conclusion. Viewed that way, the apparent Simpson’s paradox isn’t actually a paradox; it merely shows impressively that making causal claims requires making causal assumptions.</p>
</section>
<section id="association-and-causation" class="level2">
<h2 class="anchored" data-anchor-id="association-and-causation">Association and Causation</h2>
<p>Whether you have engaged in some data analysis yourself or followed a heated discussion about the correct way to interpret some data on Twitter, you have likely heard of the mantra “correlation doesn’t imply causation.” To see what this means, let’s have a look at an example. As it turns out, the yearly number of non-commercial space launches has a high degree of correlation with the yearly number of sociology doctorates awarded in the United States.</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="spurious_correlation.png" class="img-fluid figure-img" width="800"></p>
<p></p><figcaption class="figure-caption">Correlation of non-commercial space launches and sociology doctorates awarded in the US</figcaption><p></p>
</figure>
</div>
<p>We can probably agree there are no causal relationships at play here, meaning that this is a spurious correlation. Many more examples like this, showcasing fun but meaningless correlations, can be found on Tyler Vigen’s very entertaining website <a href="https://www.tylervigen.com/spurious-correlations">spurious correlations</a>.</p>
<p>It is actually relatively easy to stumble upon such spurious correlations. If you collect a large enough dataset (or generate one yourself with just random data) you will find correlations between some variables that are entirely due to chance. More importantly, however, correlation can be (and often is) caused by <strong>confounding variables</strong> (also called confounders or lurking variables). An example: You might find a positive correlation between ice cream sales and the number of shark attacks. It is safe to assume that this isn’t due to ice cream somehow attracting sharks or shark attacks causing people to console themselves with ice cream. Instead there is a confounding variable: temperature. Higher temperatures not only cause more people to enjoy some ice cream, they also cause more people to go for a swim in the ocean risking an unfortunate encounter with a shark. Thus, we say that the correlation between both variables is due to confounding.</p>
<p>Since correlation is merely a measure of <em>linear</em> statistical dependence, it is better to use the term <strong>association</strong> when referring to statistical dependence in general. But what does it really mean when we say “association is not causation” or “association does not imply causation”? In essence, this means that the amount of association and the amount of causation between two variables can be different. It is possible that none of the association is causal (probably like in the example of space launches and sociology doctorates) and it is also possible that some or even all of the association is causal. This is what motivates the field of causal inference. With statistical tools alone it is not possible to determine the amount of causation hiding behind association. Instead we have to specifically address the causal mechanisms that are generating our data.</p>
</section>
<section id="causal-inference-in-data-science" class="level2">
<h2 class="anchored" data-anchor-id="causal-inference-in-data-science">Causal Inference in Data Science</h2>
<p>Having established the need for causal inference, what is its role in the realm of data science? A useful mental model is to distinguish between three different tasks (<a href="https://www.tandfonline.com/doi/full/10.1080/09332480.2019.1579578">Hernan, Hsu &amp; Healy, 2019</a>): description, prediction, and causal inference.</p>
<p><em>Descriptive analysis</em> is usually based on quantitative summaries of variables of interest and involves methods ranging from simple counts or proportions to sophisticated data visualizations or even more advanced techniques like unsupervised clustering. The goal is to describe the properties of some data, which, in and of itself, can help us understand aspects of the world that we are interested in. For example, a task that would be descriptive in nature is gathering the distribution of household heating sources by region. This might reveal patterns that can be used to inform policy decisions.</p>
<p><em>Predictive modeling</em> aims to generate accurate predictions of a variable (or some variables). In a prediction task, we only care about the predictive performance and generalization power of our model and will exploit any available variable that helps us in this regard. That is, we look for predictive information and not for causal information, which is why we should never assume that a given coefficient in a predictive model has a causal interpretation. A good example is the prediction of used car prices using features like age and mileage. The exact nature of the causal relationships at play here is not really relevant, we simply want to exploit all the information that is useful for our prediction task.</p>
<p>Finally, <em>causal inference</em> aims to understand the impact of one variable, often called the <strong>treatment</strong>, on another variable, often called the <strong>outcome</strong>. That is, we want to find that part of the association between the treatment and the outcome that is causal in nature. For example, we might want to find the causal effect of air pollution on life expectancy or the causal effect of one-time bonus payments on employee retention. Thinking back to our example with Simpson’s paradox, the important point is that making valid causal inferences requires us to consider the causal mechanisms that generated our data.</p>
<p>Of course, this is not to say that description, prediction, and causal inference are not related. They do, in fact, overlap in some respects: Descriptive analysis increases our understanding of the data no matter what we ultimately try to achieve and in some cases (i.e., if the causal structure of the data allows it) can actually be used to discern causal relationships. Also, while predictive models aren’t generally good causal models because they only care about predictive performance (which often goes hand in hand with introducing biases), some part of their predictive power stems from the causal relationships in the data. Causal models, on the other hand, do have some predictive power because the causal effect of the treatment tells us something about the outcome.</p>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>Causal inference is an essential tool for rigorous decision-making. Without addressing the causal structure of our data, we can only make associational claims – but what we actually often aspire to do is make causal claims. That is, we don’t merely want to know whether patients who got some treatment eventually got better, we want to know whether they got better <em>because of</em> the treatment. This is the purpose of causal inference.</p>
<p>In the following blog posts of this series we’ll discuss the topic in much more depth. We’ll go into how we can articulate causal assumptions, how we can build causal models and link them to our data, and how we can finally answer our causal questions in a wide range of different settings.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>